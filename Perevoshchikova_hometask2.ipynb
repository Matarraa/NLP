{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1fe39dd",
   "metadata": {},
   "source": [
    "PS Надеюсь, полчаса от полуночи еще входят в 2 дня после дедлайна (я перепутала часовые пояса)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db80a8ba",
   "metadata": {},
   "source": [
    "Для разметки корпуса я выбрала данный тегсет (https://universaldependencies.org/u/pos/index.html), поскольку он, на мой взгляд, достаточно универсален и имеет более \"типичные\" и обобщенные теги. И эти же теги используются в библиотеке Natasha.\n",
    "В отобранных мной предложениях встречаются следующие сложные для pos-теггинга моменты: аббревиатуры, сокращения, омоформы, числительные (в том числе порядковые, такие как \"13-й\"), имена собственные и заимствованные слова. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "91d50858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "morph = MorphAnalyzer()\n",
    "from pymystem3 import Mystem\n",
    "m = Mystem()\n",
    "import re\n",
    "import spacy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a49946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('text.txt', encoding = 'utf-8') as file:\n",
    "        text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dd82b357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.0.9-py2.py3-none-any.whl (242 kB)\n",
      "\u001b[K     |████████████████████████████████| 242 kB 2.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting et-xmlfile\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.0.9\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.9/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ba7b1931",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"CORPUS.xlsx\")\n",
    "words_corpus = {}\n",
    "for row in df.itertuples():\n",
    "    words_corpus[str(row.word).lower()] = row.POS  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150158f6",
   "metadata": {},
   "source": [
    "## Прогоняем текст через Mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7449d53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ana = m.analyze(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bea32636",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_mystem = {}\n",
    "for word in ana:\n",
    "    if 'analysis' in word:\n",
    "        if word['analysis'] == []:\n",
    "            words_mystem[word['text']] = 'X'\n",
    "        else:\n",
    "            gr = word['analysis'][0]['gr']\n",
    "            pos = gr.split('=')[0].split(',')[0]\n",
    "            if pos == 'A':\n",
    "                pos = 'ADJ'\n",
    "            elif pos == 'PR':\n",
    "                pos = 'ADP'\n",
    "            elif pos == 'V':\n",
    "                pos = 'VERB'\n",
    "            elif pos == 'CONJ':\n",
    "                pos = 'CCONJ'\n",
    "            elif pos == 'ADVPRO':\n",
    "                pos = 'ADV'\n",
    "            elif pos in ['APRO', 'SPRO']:\n",
    "                pos = 'PRON'\n",
    "            elif pos == 'ANUM':\n",
    "                pos = 'NUM'\n",
    "            elif pos == 'S':\n",
    "                pos = 'NOUN'\n",
    "            words_mystem[word['text'].lower()] = pos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7be5f39",
   "metadata": {},
   "source": [
    "## Прогоняем текст через pymorphy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3c852751",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = re.sub(r'[^\\w\\s]','', text)\n",
    "words_pymorphy = {}\n",
    "for token in text1.split():\n",
    "    ana2 = morph.parse(token)\n",
    "    first = ana2[0]\n",
    "    pos = str(first.tag.POS)\n",
    "    if pos in ['ADJF', 'ADJS']:\n",
    "        pos = 'ADJ'\n",
    "    elif pos == 'PREP':\n",
    "        pos = 'ADP'\n",
    "    elif pos == 'CONJ':\n",
    "        pos = 'CCONJ'\n",
    "    elif pos == 'ADVB':\n",
    "        pos = 'ADV'\n",
    "    elif pos in ['PRTS', 'PRTF', 'GRND']:\n",
    "        pos = 'VERB'\n",
    "    elif pos == 'PRCL':\n",
    "        pos = 'PART'\n",
    "    elif pos == 'COMP':\n",
    "        pos = 'ADJ'\n",
    "    elif pos == 'INFN':\n",
    "        pos = 'VERB'\n",
    "    elif pos == 'NUMR':\n",
    "        pos = 'NUM'\n",
    "    elif pos == 'NPRO':\n",
    "        pos = 'PRON' \n",
    "    elif pos == 'PRED':\n",
    "        pos = 'ADV'\n",
    "    elif pos == 'None':\n",
    "        pos = 'X'\n",
    "    words_pymorphy[str(first.word)] = pos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974f3e34",
   "metadata": {},
   "source": [
    "## Прогоняем текст через Natasha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "76fac0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: natasha in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (1.4.0)\n",
      "Requirement already satisfied: razdel>=0.5.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from natasha) (0.5.0)\n",
      "Requirement already satisfied: ipymarkup>=0.8.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from natasha) (0.9.0)\n",
      "Requirement already satisfied: pymorphy2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from natasha) (0.9.1)\n",
      "Requirement already satisfied: navec>=0.9.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from natasha) (0.10.0)\n",
      "Requirement already satisfied: yargy>=0.14.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from natasha) (0.15.0)\n",
      "Requirement already satisfied: slovnet>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from natasha) (0.5.0)\n",
      "Requirement already satisfied: intervaltree>=3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from ipymarkup>=0.8.0->natasha) (3.1.0)\n",
      "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from intervaltree>=3->ipymarkup>=0.8.0->natasha) (2.4.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from navec>=0.9.0->natasha) (1.20.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pymorphy2->natasha) (2.4.417127.4579844)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pymorphy2->natasha) (0.7.2)\n",
      "Requirement already satisfied: docopt>=0.6 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pymorphy2->natasha) (0.6.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.9/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install natasha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f3ffe4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,\n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    PER,\n",
    "    Doc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4fae30f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmenter = Segmenter()\n",
    "morph_vocab = MorphVocab()\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "doc = Doc(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a38b2a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.segment(segmenter)\n",
    "doc.tag_morph(morph_tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8b77fc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_natasha = {}\n",
    "for token in doc.tokens:\n",
    "    if token.pos != 'PUNCT':\n",
    "        words_natasha[token.text.lower()] = token.pos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a6ddd3",
   "metadata": {},
   "source": [
    "### Проверяем точность автоматического посттеггинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7eb9c384",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "621c66bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy (words_auto, words_corpus):\n",
    "    gold = []\n",
    "    results = []\n",
    "    for key in words_corpus:\n",
    "        gold.append(words_corpus[key])\n",
    "        if key in words_auto:\n",
    "            results.append(words_auto[key])\n",
    "        else:\n",
    "            results.append('None')  \n",
    "    print(\"Accuracy: %.4f\" % accuracy_score(results, gold)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "428e657a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8491\n"
     ]
    }
   ],
   "source": [
    "#natasha\n",
    "accuracy(words_natasha, words_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "07d7e53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7862\n"
     ]
    }
   ],
   "source": [
    "#pymorphy\n",
    "accuracy(words_pymorphy, words_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cecc19bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8113\n"
     ]
    }
   ],
   "source": [
    "#mystem\n",
    "accuracy(words_mystem, words_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f62a467",
   "metadata": {},
   "source": [
    "Лучший результат показала Natasha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7544ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, s in enumerate(doc.sents):\n",
    "    for t in s:\n",
    "\n",
    "      if adj == '':\n",
    "        if t.pos_ == 'ADJ':\n",
    "          adj = t.text\n",
    "\n",
    "      else :\n",
    "        if t.pos_ == 'NOUN':\n",
    "          print(adj, ' ', t.text)\n",
    "          adj = ''\n",
    "        elif t.pos_ != 'ADJ':\n",
    "            adj = ''  \n",
    "        else:\n",
    "            adj = t.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac89469",
   "metadata": {},
   "source": [
    "## Chunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fad39145",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adj + noun/ adp + noun/ pos + и + pos\n",
    "def chunker (first, second, third, words_natasha):\n",
    "    n_gramms = []\n",
    "    words = ''\n",
    "    if third == '':\n",
    "        for token in doc.tokens:\n",
    "            if words == '':\n",
    "                if token.pos == first:\n",
    "                    words = token.text.lower()\n",
    "            else:\n",
    "                if token.pos == second:\n",
    "                    n_gramms.append(words+' '+token.text.lower())\n",
    "                    words = ''\n",
    "                elif token.pos != first:\n",
    "                    words = ''\n",
    "                else:\n",
    "                    words = token.text.lower()\n",
    "    else:\n",
    "        words_3 = []\n",
    "        for token in doc.tokens:\n",
    "            if words_3 == []:\n",
    "                if token.pos == first:\n",
    "                    words_3.append(token.text.lower())\n",
    "            elif len(words_3) == 1:\n",
    "                if token.text.lower() == second:\n",
    "                    words_3.append(token.text.lower())\n",
    "                elif token.pos != first:\n",
    "                    words_3 = []\n",
    "                else:\n",
    "                    words_3.append(token.text.lower()) \n",
    "            else:\n",
    "                if token.pos == third:\n",
    "                    words_3.append(token.text.lower())\n",
    "                    n_gramms.append(words_3[0]+' '+words_3[1]+' '+words_3[2])    \n",
    "                    words_3 = []\n",
    "                elif token.text.lower() != second:\n",
    "                    words_3 = []\n",
    "                else:\n",
    "                    words_3.append(token.text.lower())\n",
    "    return n_gramms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ad7df38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['железными и бетонными']\n"
     ]
    }
   ],
   "source": [
    "print(chunker ('ADJ', 'и', 'ADJ', doc.tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cceb7f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['смотрят и веселятся']\n"
     ]
    }
   ],
   "source": [
    "print(chunker ('VERB', 'и', 'VERB', doc.tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "63e66b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['в пресс-службе', 'в ответ', 'на запрос', 'на вопрос', 'в мире', 'против кори', 'на платформе', 'на льду', 'о ступеньку', 'на стол', 'в печи']\n"
     ]
    }
   ],
   "source": [
    "print(chunker ('ADP', 'NOUN', '', doc.tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "624bf547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['бетонными опорами', 'стеклянных гирляндах', 'провисают провода', 'российские загсы', 'государственной регистрации', 'отечественной ономастики', '13-м знаком', '2011 году', 'зодиакальный круг', 'японские астрономы', '2002 г', 'абсолютный оффтопп', 'прямое отношение', 'замечательные кадры']\n"
     ]
    }
   ],
   "source": [
    "print(chunker ('ADJ', 'NOUN', '', doc.tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32b7301",
   "metadata": {},
   "source": [
    "## 5-ое задание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd0372b",
   "metadata": {},
   "source": [
    "Поскольку в предыдущей домашней работе я скачивала отзывы от кофе, было бы здорово добавить шаблоны \"средний + NOUN\" (потому что \"средняя кислотность\" - это скорее хорошо, а \"средний вкус\" - плохо), а также рассмотрела бы шаблоны \"очень +  VERB\", \"очень + ADJ\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
