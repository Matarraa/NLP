{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fb4657b",
   "metadata": {},
   "source": [
    "## Скачиваем отзывы "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ecc7864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import re\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d57e686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "morph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a8dde058",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8cedba",
   "metadata": {},
   "source": [
    "### Берем все отзывы со страницы. Каждый пользователь оценивает магазин и доставку, поэтому нам необходимо выкидывать из выборки каждый второй отзыв. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e333663",
   "metadata": {},
   "outputs": [],
   "source": [
    "#функция делает список ссылок на страницы с отзывами\n",
    "def list_of_urls (url):\n",
    "    list_of_urls = []\n",
    "    for i in range (2, 8):\n",
    "        new_url = url + '&page=' + str(i)\n",
    "        list_of_urls.append(new_url)\n",
    "    return list_of_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ce9c7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#функция пробегается по страницам с отзывами, собирает отзывы, выкидывая из них каждый второй\n",
    "def comments (list_of_urls, file):\n",
    "    for url in list_of_urls:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text)\n",
    "        comments = soup.find_all('p', {'class': 'review-text'})\n",
    "        for i in range (0, len(comments), 2):\n",
    "            txt = str (comments[i])\n",
    "            txt1 = re.sub ('<.*>','', txt)\n",
    "            text = re.sub ('\\s+', ' ', txt1) \n",
    "            with open(file, 'a', encoding='utf-8') as f:\n",
    "                f.write (text + '\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ff6c36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('negative_comments.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1296dd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('positive_comments.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d743eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ссылки на страницы с негативными отзывами\n",
    "urls_neg = list_of_urls ('https://shop.tastycoffee.ru/reviews?shop=1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cc871a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ссылки на страницы с положительными отзывами\n",
    "urls_pos = list_of_urls ('https://shop.tastycoffee.ru/reviews?shop=5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1afd70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#выкачиваем негативные отзывы (58)\n",
    "comments(urls_neg, 'negative_comments.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d23d595",
   "metadata": {},
   "outputs": [],
   "source": [
    "#выкачиваем положительные отзывы (60)\n",
    "comments(urls_pos, 'positive_comments.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6e4fc134",
   "metadata": {},
   "outputs": [],
   "source": [
    "#отзывы для проверки\n",
    "def comments_chek (file):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()[54:]\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eae64465",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_10 = []\n",
    "comments_10.extend(comments_chek ('negative_comments.txt'))\n",
    "comments_10.extend(comments_chek ('positive_comments.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02dbf4c",
   "metadata": {},
   "source": [
    "### Токенизируем и приведем к начальной форме"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8ae214b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#функция токенизирует и приводит слова в отзывах к начальной форме\n",
    "def token_lemma (file):\n",
    "    words = []\n",
    "    tokens = []\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()[0:55]\n",
    "        for line in lines:\n",
    "            tokens.extend([w.lower() for w in word_tokenize(line) if w.isalpha()])\n",
    "            for token in tokens:\n",
    "                ana = morph.parse(token)[0].normal_form\n",
    "                words.append(ana)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "14b4a9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_neg = token_lemma ('negative_comments.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e467b583",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_pos = token_lemma ('positive_comments.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a9aeca23",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_pos = Counter(words_pos)\n",
    "freq_neg = Counter(words_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3af43354",
   "metadata": {},
   "outputs": [],
   "source": [
    "#создадим частотные словари со словами, которые встречаются только в негативных/позитивных отзывах\n",
    "only_neg = {}\n",
    "only_pos = {}\n",
    "for key in freq_pos:\n",
    "    if key not in freq_neg and freq_pos[key] > 5:\n",
    "        only_pos[key] = freq_pos[key]\n",
    "        \n",
    "for key in freq_neg:\n",
    "    if key not in freq_pos and freq_neg[key] > 5:\n",
    "        only_neg[key] = freq_neg[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4593110",
   "metadata": {},
   "source": [
    "### Функция, которая определяет положительный отзыв или отрицательный"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6c662339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comment_detect(only_pos, only_neg, text): \n",
    "    counts = {'pos' : 0, 'neg' : 0}\n",
    "    words = []\n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    for token in nltk.word_tokenize(text):\n",
    "        ana = morph.parse(token)[0].normal_form\n",
    "        words.append(ana) \n",
    "    for word in words:\n",
    "        if word in only_pos:\n",
    "            counts['pos'] += 1\n",
    "        elif word in only_neg:\n",
    "            counts['neg'] += 1\n",
    "        else:\n",
    "            continue\n",
    "    if counts['pos'] > counts['neg']:\n",
    "        mood = 'positive'\n",
    "    elif counts['pos'] == counts['neg']:\n",
    "        mood = 'neutral'\n",
    "    else:\n",
    "        mood = 'negative'\n",
    "    return mood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb58f6e",
   "metadata": {},
   "source": [
    "В нашем списке отзывов для проверки первые 4 отзыва отрицательные, остальные 6 - положительные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "31cdf7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from sklearn) (0.24.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.20.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.6.3)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.9/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0ddbbaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f8408c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#оценка качества при помощи accuracy\n",
    "def accuracy (comments_10, only_pos, only_neg):\n",
    "    results = []\n",
    "    gold = []\n",
    "    for comment in comments_10[0:4]:\n",
    "        results.append(comment_detect(only_pos, only_neg, comment))\n",
    "        gold.append('negative')\n",
    "    for comment in comments_10[4:10]:\n",
    "        results.append(comment_detect(only_pos, only_neg, comment))\n",
    "        gold.append('positive')\n",
    "    print(\"Accuracy: %.4f\" % accuracy_score(results, gold))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "331d1f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8000\n"
     ]
    }
   ],
   "source": [
    "accuracy(comments_10, only_pos, only_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07b4dc9",
   "metadata": {},
   "source": [
    "### Предложения по улучшению программы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78f087e",
   "metadata": {},
   "source": [
    "Во-первых, для точности программы было бы неплохо накачать большее количество отзывов. Во-вторых, в ходе выполнения программы, я заметила, что она достаточно туго справлялась с токенизацией и приведением к начальной форме слов из отзывов. Изначально для этого я попыталась использовать mystem, так как качество его лемматизации лучше, но скорость программы в данном случае сильно страдала. В связи с этим, было принято решение использовать nltk и pymorthy, что значительно ускорило программу. Однако стоит отметить, что файлы с отзывами я прочитывала через readlines(), что не подойдет, если файлы будут весить гораздо больше. Большие файлы следует читать построчно. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
